{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915a2e90-2cdc-4164-b329-7761e4038674",
   "metadata": {},
   "source": [
    "# Tutorial 05: MCMC over v_turb on a synthetic RADJAX dataset\n",
    "\n",
    "The tutorial illustrates how to:\n",
    "\n",
    "1. Generate a synthetic observation from a parametric protoplanetary disk model.\n",
    "2. Save the observation (spectral cube + metadata) to a FITS file.\n",
    "3. Set up a simple MCMC sampler over the microturbulent velocity parameter `v_turb`.\n",
    "4. Run [`emcee`](https://emcee.readthedocs.io/en/stable/) to recover `v_turb`.\n",
    "5. Save all experimental settings and results to a YAML file for reproducibility.\n",
    "\n",
    "We use the `broken_power_law` model implemented in RADJAX as our forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399949c4-1c14-4872-a47b-348c707a2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)  \n",
    "\n",
    "from astropy.io import fits\n",
    "import emcee\n",
    "import yaml\n",
    "\n",
    "from radjax import inference\n",
    "from radjax import sensor\n",
    "from radjax import utils\n",
    "from radjax import chemistry as chem\n",
    "from radjax.models import broken_power_law as disk_model\n",
    "from radjax.models.broken_power_law import forward_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ee08b-2bd8-429b-aac4-97e934128495",
   "metadata": {},
   "source": [
    "## Load parameters and build baseline scene\n",
    "\n",
    "We begin by loading disk, observation, and chemistry parameters, building the\n",
    "baseline disk structure, and constructing rays and frequencies. These form the\n",
    "static context of the SamplerState."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2501b3d0-a1ef-4797-8725-ee712fb88cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_freqs = 20\n",
    "npix      = 200\n",
    "rng_seed_synth = 1234  # for JAX noise\n",
    "numpy_seed     = 2025  # for emcee RNG\n",
    "\n",
    "params_path  = \"./tutorial01_params.yaml\"   # produced in Tutorial 01/02\n",
    "\n",
    "# load baseline params\n",
    "disk_params = disk_model.disk_from_yaml(params_path)\n",
    "obs_params  = sensor.params_from_yaml(params_path)\n",
    "chem_params = chem.chemistry_from_yaml_path(params_path)\n",
    "mol         = chem.load_molecular_tables(chem_params)\n",
    "\n",
    "# precompute base disk grids\n",
    "temperature, v_phi, co_nd, base_disk = disk_model.co_disk_from_params(\n",
    "    disk_params, chem_params\n",
    ")\n",
    "\n",
    "# frequency grid\n",
    "freqs = sensor.compute_camera_freqs(\n",
    "    num_freqs=num_freqs,\n",
    "    width_kms=obs_params.velocity_width_kms,\n",
    "    nu0=mol.nu0\n",
    ")\n",
    "\n",
    "# sky grid and rays\n",
    "xaxis = yaxis = np.linspace(-obs_params.fov/2, obs_params.fov/2, npix)\n",
    "x_sky, y_sky = jnp.meshgrid(xaxis, yaxis, indexing=\"xy\")\n",
    "rays = sensor.rays_from_params(obs_params, x_sky, y_sky)\n",
    "\n",
    "# SamplerState (static context)\n",
    "state = inference.SamplerState(\n",
    "    obs_params=obs_params,   \n",
    "    disk_params=disk_params,        \n",
    "    chem_params=chem_params,\n",
    "    base_disk=base_disk,\n",
    "    rays=rays,               \n",
    "    mol=mol,      \n",
    "    beam=None,\n",
    "    use_pressure_correction=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d90b2-ea9c-48a7-b0e3-14f457ee16d3",
   "metadata": {},
   "source": [
    "## Define θ → DiskParams adapter\n",
    "We now define a minimal adapter that maps a one-dimensional parameter vector θ = [v_turb] to a new `DiskParams` object. <br>\n",
    "This isolates the **dynamic** parameters (sampled each MCMC step) from the **static** state.\n",
    "\n",
    "We add this adapter to the state and also add the noise parameter `sigma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e3fbf0-faf7-4bcb-a30b-5f8b5d99bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VTurbAdapter:\n",
    "    def apply(self, disk_params, theta: jnp.ndarray):\n",
    "        return disk_params.replace(v_turb=theta[0])\n",
    "\n",
    "state = state.replace(\n",
    "    sigma=10.0,               # Jy/pixel\n",
    "    adapter=VTurbAdapter()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd0ba97-e428-45a4-b7dc-9f2ff40f0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_turb_true = 0.32 \n",
    "\n",
    "disk_true = state.adapter.apply(state.disk_params, jnp.array([v_turb_true]))\n",
    "cube_true = forward_model(disk_params=disk_true, freqs=freqs, state=state, output=\"image\")\n",
    "\n",
    "# add Gaussian noise (use the same sigma as in state)\n",
    "jax_seed = 42\n",
    "key = jax.random.PRNGKey(42)       # reproducible seed\n",
    "noise = state.sigma * jax.random.normal(key, shape=cube_true.shape)\n",
    "cube_obs = cube_true + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad44abdc-54c9-47b8-96c9-ece0aeccce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Saved FITS → ./tutorial05_artifacts/synthetic_observation.fits\n"
     ]
    }
   ],
   "source": [
    "# save to FITS\n",
    "fits_path = \"./tutorial05_artifacts/synthetic_observation.fits\"\n",
    "utils.save_synthetic_observation(\n",
    "    filepath=fits_path,\n",
    "    cube_obs=cube_obs,\n",
    "    freqs=freqs,\n",
    "    nu0=mol.nu0,\n",
    "    sigma=state.sigma,\n",
    "    noise_type=\"jax.random.normal\",\n",
    "    seed=jax_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8bc2a-d4f6-484e-b1cb-d470bf6c032e",
   "metadata": {},
   "source": [
    "## Define prior, likelihood, and emcee target\n",
    "\n",
    "We implement a flat prior on `v_turb`, a `JAX-JIT` forward model, and a Gaussian pixel likelihood. <br>\n",
    "Together these form the log-posterior used by `emcee`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e51d44f-d908-4747-aa5b-935dd958365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = 0.0, 2.0\n",
    "\n",
    "def logprior(theta_np: np.ndarray) -> float:\n",
    "    v = float(theta_np[0])\n",
    "    return 0.0 if (vmin <= v <= vmax) else -np.inf\n",
    "\n",
    "@jax.jit\n",
    "def render_image_from_theta(theta_jnp: jnp.ndarray) -> jnp.ndarray:\n",
    "    disk_state = state.adapter.apply(state.disk_params, theta_jnp)\n",
    "    return forward_model(disk_params=disk_state, freqs=freqs, state=state, output=\"image\")\n",
    "\n",
    "def loglikelihood(theta_np: np.ndarray) -> float:\n",
    "    cube_model = render_image_from_theta(jnp.asarray(theta_np))\n",
    "    residual = (cube_model - cube_obs) / state.sigma\n",
    "    return -0.5 * np.sum(residual * residual)\n",
    "\n",
    "# emcee target\n",
    "def logprob(theta_np: np.ndarray) -> float:\n",
    "    lp = logprior(theta_np)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + loglikelihood(theta_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aca3c4-45fa-4ccc-b55a-0fc6d6d57d08",
   "metadata": {},
   "source": [
    "## Run MCMC with emcee\n",
    "\n",
    "We now run an ensemble sampler with 32 walkers for 100 steps. <br> \n",
    "The sampler explores the posterior distribution of `v_turb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbb96f52-0aed-402f-ac9e-430fdff02fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:18<00:00,  9.15s/it]\n"
     ]
    }
   ],
   "source": [
    "numpy_seed = 2025 \n",
    "np.random.seed(numpy_seed)\n",
    "\n",
    "ndim = 1\n",
    "nwalkers = 10\n",
    "nsteps   = 2\n",
    "\n",
    "# Set up a backend\n",
    "# Don't forget to clear it in case the file already exists\n",
    "filename = \"tutorial05_artifacts/emcee_state.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "backend.reset(nwalkers, ndim)\n",
    "\n",
    "p0 = np.random.uniform(vmin, vmax, size=(nwalkers, ndim))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, logprob, backend=backend)\n",
    "emcee_state = sampler.run_mcmc(p0, nsteps, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b08179-6eda-4186-a3ce-71abc3e9cdfb",
   "metadata": {},
   "source": [
    "## Summarize results and posterior predictive check\n",
    "\n",
    "We extract the MAP and median estimates for `v_turb`, compute the 68%\n",
    "credible interval, and compare the posterior predictive cube to the synthetic\n",
    "observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ec06ac-ba93-42b6-920a-9644dd6428e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True v_turb: 0.32\n",
      "MAP  v_turb: 0.32 \n",
      "MED  v_turb: 0.95 (68% CI: 0.3, 1.8)\n",
      "Posterior predictive RMS (MAP): 9.9942\n"
     ]
    }
   ],
   "source": [
    "chain = sampler.get_chain(flat=True)[:, 0]\n",
    "logp  = sampler.get_log_prob(flat=True)\n",
    "\n",
    "v_map = chain[np.argmax(logp)]\n",
    "v_med = np.median(chain)\n",
    "v_lo, v_hi = np.percentile(chain, [16, 84])\n",
    "\n",
    "print(f\"True v_turb: {v_turb_true:.2f}\")\n",
    "print(f\"MAP  v_turb: {v_map:.2f} \")\n",
    "print(f\"MED  v_turb: {v_med:.2f} (68% CI: {v_lo:.1f}, {v_hi:.1f})\")\n",
    "\n",
    "# posterior predictive at MAP\n",
    "disk_map = state.adapter.apply(state.disk_params, jnp.array([v_map]))\n",
    "cube_map = forward_model(disk_params=disk_map, freqs=freqs, state=state, output=\"image\")\n",
    "rms = np.sqrt(np.mean((np.asarray(cube_map) - cube_obs)**2))\n",
    "print(f\"Posterior predictive RMS (MAP): {rms:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ccaddf-8b47-48a6-b040-a15739b5df24",
   "metadata": {},
   "source": [
    "## Save MCMC configuration and results to YAML\n",
    "\n",
    "Finally, we save all experimental parameters, priors, sampler settings,\n",
    "and results into a compact YAML file for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcd35f22-e57e-4be8-bb38-d00687623a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_params = {\n",
    "    \"method\": \"emcee\",\n",
    "    \"numpy_seed\": numpy_seed,\n",
    "    \"nwalkers\": nwalkers,\n",
    "    \"nsteps\": nsteps,\n",
    "    \"sampled_params\": [\"v_turb\"],\n",
    "    \"bounds\": {\"v_turb\": [vmin, vmax]}\n",
    "}\n",
    "\n",
    "results = {\n",
    "    \"v_turb_true\": v_turb_true,\n",
    "    \"v_turb_map\": v_map,\n",
    "    \"v_turb_med\": v_med,\n",
    "    \"v_turb_ci68\": [v_lo, v_hi],\n",
    "    \"rms_map\": rms\n",
    "}\n",
    "\n",
    "output_yaml_path = \"tutorial05_artifacts/params-and-mcmc-results.yaml\"\n",
    "disk_model.params_to_yaml_path(disk_true, output_yaml_path)\n",
    "chem.chemistry_to_yaml_path(chem_params, output_yaml_path)\n",
    "inference.append_inference_to_yaml(output_yaml_path, mcmc_params, results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
